function Regressor = trainForcingModel(vrTrain,vrVal,method,opt)
%trainForcingModel Train Machine Learning model [unfinished]
%
%    Regressor = trainForcingModel(vrTrain,vrVal,method,opt) trains a
%    Machine Learning (ML) model, using the columns of vrTrain as
%    predictors for the response variable vrVal. The type of ML method is
%    specified by "method", and can be a RandomForestRegressor,
%    RegressionTree, Multilayer Perceptron, etc. The model output can be
%    used with the MATLAB function predict.m to make predictions. Optional
%    arguments are provided to specify the number of regression trees and
%    splits. Other properties can be edited within the function.
% 
%    Note: This function is a placeholder and unfinished.
%
   
%   Copyright 2023 Elise Jonsson

arguments
    vrTrain (:,:)
    vrVal (:,:)
    method {mustBeMember(method,["RandomForestRegressor","RegressionTree",...
        "RegressionTreeOptim","MultilayerPerceptron","LSTM"])} = "RandomForestRegressor"
    opt.MaxNumSplits (1,1) {mustBePositive} = 20;
    opt.TreeSize (1,1) {mustBePositive} = 20;
end

switch method
    case "RandomForestRegressor"

        Regressor = TreeBagger( ...
            opt.TreeSize, ...
            vrTrain{1},vrTrain{2}, ...
            'Method','regression');

    case "RegressionTree"
        
        tree = templateTree('MaxNumSplits',opt.MaxNumSplits);

        Regressor = fitrensemble( ...
            vrTrain{1},vrTrain{2}, ...
            'Learners',tree, ...
            'NumLearningCycles',20);

    case "RegressionTreeOptim"

        tree = templateTree( ...
            'MaxNumSplits',opt.MaxNumSplits,...
            'Reproducible',true);

        Regressor = fitrensemble(vrTrain{1},vrTrain{2}, ...
            'OptimizeHyperparameters','auto', ...
            'Learners',tree, ...
            'HyperparameterOptimizationOptions', ...
            struct('AcquisitionFunctionName','expected-improvement-plus'));

    case "MultilayerPerceptron"
        
        inputSize = size(vrTrain{1},2);

        layers = [
            sequenceInputLayer(inputSize,'Normalization','zscore')
            fullyConnectedLayer(20)
            reluLayer
            fullyConnectedLayer(1)
            regressionLayer
            ];

        options = trainingOptions('adam', ...
            'Plots','none', ...
            'Verbose',true, ...
            'OutputNetwork','best-validation-loss', ...
            'Shuffle','every-epoch', ...
            'MaxEpochs',200, ...
            'InitialLearnRate',1e-2, ...
            'LearnRateDropFactor',1, ...
            'LearnRateSchedule','piecewise', ...
            'GradientThreshold',1, ...
            'ValidationData',{vrVal{1}',vrVal{2}'}, ...
            'ValidationFrequency',1e2 ...
            );

        [Regressor,info] = trainNetwork(vrTrain{1}',vrTrain{2}',layers,options);

    case "LSTM"

        inputSize = size(vrTrain{1},2);

        layers = [
            sequenceInputLayer(inputSize,'Normalization','zscore')
            lstmLayer(10,'BiasInitializer','narrow-normal')
            fullyConnectedLayer(1)
            regressionLayer
            ];

        options = trainingOptions('adam', ...
            'Plots','none', ...
            'Verbose',true, ...
            'OutputNetwork','best-validation-loss', ...
            'Shuffle','every-epoch', ...
            'MaxEpochs',100, ...
            'InitialLearnRate',1e-2, ...
            'LearnRateDropFactor',1, ...
            'LearnRateSchedule','piecewise', ...
            'GradientThreshold',1, ...
            'ValidationData',{vrVal{1}',vrVal{2}'}, ...
            'ValidationFrequency',1e2 ...
            );

        [Regressor,info] = trainNetwork(vrTrain{1}',vrTrain{2}',layers,options);
end

% switch method
%     case "MultilayerPerceptron"
%         disp("Validation RMSE: "+info.FinalValidationRMSE)
%     otherwise
%         disp("Resubstitution Loss: "+resubLoss(Regressor))
% end

end